{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Food Product</th>\n",
       "      <th>Main Ingredient</th>\n",
       "      <th>Sweetener</th>\n",
       "      <th>Fat/Oil</th>\n",
       "      <th>Seasoning</th>\n",
       "      <th>Allergens</th>\n",
       "      <th>Price ($)</th>\n",
       "      <th>Customer rating (Out of 5)</th>\n",
       "      <th>Prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Almond Cookies</td>\n",
       "      <td>Almonds</td>\n",
       "      <td>Sugar</td>\n",
       "      <td>Butter</td>\n",
       "      <td>Flour</td>\n",
       "      <td>Almonds, Wheat, Dairy</td>\n",
       "      <td>10.15</td>\n",
       "      <td>3.1</td>\n",
       "      <td>Contains</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Almond Cookies</td>\n",
       "      <td>Almonds</td>\n",
       "      <td>Sugar</td>\n",
       "      <td>Butter</td>\n",
       "      <td>Flour</td>\n",
       "      <td>Almonds, Wheat, Dairy</td>\n",
       "      <td>6.17</td>\n",
       "      <td>4.5</td>\n",
       "      <td>Contains</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Chicken Noodle Soup</td>\n",
       "      <td>Chicken broth</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Salt</td>\n",
       "      <td>Chicken, Wheat, Celery</td>\n",
       "      <td>19.65</td>\n",
       "      <td>4.1</td>\n",
       "      <td>Contains</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Chicken Noodle Soup</td>\n",
       "      <td>Chicken broth</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Salt</td>\n",
       "      <td>Chicken, Wheat, Celery</td>\n",
       "      <td>17.48</td>\n",
       "      <td>4.7</td>\n",
       "      <td>Contains</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cheddar Cheese</td>\n",
       "      <td>Cheese</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Salt</td>\n",
       "      <td>Dairy</td>\n",
       "      <td>10.83</td>\n",
       "      <td>3.7</td>\n",
       "      <td>Contains</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Food Product Main Ingredient Sweetener Fat/Oil Seasoning  \\\n",
       "0       Almond Cookies         Almonds     Sugar  Butter     Flour   \n",
       "1       Almond Cookies         Almonds     Sugar  Butter     Flour   \n",
       "2  Chicken Noodle Soup   Chicken broth       NaN     NaN      Salt   \n",
       "3  Chicken Noodle Soup   Chicken broth       NaN     NaN      Salt   \n",
       "4       Cheddar Cheese          Cheese       NaN     NaN      Salt   \n",
       "\n",
       "                Allergens  Price ($)  Customer rating (Out of 5) Prediction  \n",
       "0   Almonds, Wheat, Dairy      10.15                         3.1   Contains  \n",
       "1   Almonds, Wheat, Dairy       6.17                         4.5   Contains  \n",
       "2  Chicken, Wheat, Celery      19.65                         4.1   Contains  \n",
       "3  Chicken, Wheat, Celery      17.48                         4.7   Contains  \n",
       "4                   Dairy      10.83                         3.7   Contains  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# Load the dataset\n",
    "data = pd.read_csv(\"Allergen_Status_of_Food_Products.csv\")\n",
    "\n",
    "# Display the first few rows of the dataset for exploration\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ahmed\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ahmed\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import optuna\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Preprocessing the data\n",
    "data = pd.read_csv(\"Allergen_Status_of_Food_Products.csv\")\n",
    "\n",
    "# Fill NaN values with empty strings in the relevant columns\n",
    "data = data.fillna('')\n",
    "\n",
    "# Encoding the input features using CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(data['Food Product'] + \" \" + \n",
    "                             data['Main Ingredient'] + \" \" + \n",
    "                             data['Sweetener'] + \" \" + \n",
    "                             data['Fat/Oil'] + \" \" + \n",
    "                             data['Seasoning'])\n",
    "                             \n",
    "\n",
    "# Preparing the target variable for multi-label classification\n",
    "mlb = MultiLabelBinarizer()\n",
    "y = mlb.fit_transform(data['Allergens'].str.split(', '))\n",
    "\n",
    "# Splitting the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create the model\n",
    "model = Sequential()\n",
    "model.add(Dense(128, input_dim=X_train.shape[1], activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(y_train.shape[1], activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "X_train_dense = X_train.toarray()\n",
    "X_test_dense = X_test.toarray()\n",
    "\n",
    "# Train the model with the dense data\n",
    "history = model.fit(X_train_dense, y_train, epochs=1000, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Evaluate the model on the test set using the dense data\n",
    "loss, accuracy = model.evaluate(X_test_dense, y_test)\n",
    "print(f\"Test Accuracy: {accuracy*100:.2f}%\")\n",
    "\n",
    "# Make predictions using the dense data\n",
    "predictions = model.predict(X_test_dense)\n",
    "model.save('ALE.h5')  # creates a HDF5 file 'ALE.h5'\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(trial):\n",
    "    # Hyperparameters to be tuned by Optuna\n",
    "    dropout_rate1 = trial.suggest_float('dropout_rate1', 0.1, 0.7)\n",
    "    dropout_rate2 = trial.suggest_float('dropout_rate2', 0.1, 0.7)\n",
    "\n",
    "    lr = trial.suggest_float(\"lr\", 1e-5, 1e-2, log=True)\n",
    "    units_layer_1 = trial.suggest_int('units_layer_1', 64, 256)\n",
    "    units_layer_2 = trial.suggest_int('units_layer_2', 32, 128)\n",
    "    activation_function1 = trial.suggest_categorical('activation1', ['relu', 'sigmoid', 'tanh', 'leaky_relu'])\n",
    "    activation_function2 = trial.suggest_categorical('activation2', ['relu', 'sigmoid', 'tanh', 'leaky_relu'])\n",
    "\n",
    "    # Model architecture\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units_layer_1, input_dim=X_train.shape[1], activation=activation_function1))\n",
    "    model.add(Dropout(dropout_rate1))\n",
    "    model.add(Dense(units_layer_2, activation=activation_function2))\n",
    "    model.add(Dropout(dropout_rate2))\n",
    "    model.add(Dense(y_train.shape[1], activation='sigmoid'))\n",
    "\n",
    "    # Compile model\n",
    "    optimizer = Adam(learning_rate=lr)\n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "def objective(trial):\n",
    "     # Create and train model\n",
    "    model = create_model(trial)\n",
    "    X_train_dense = X_train.toarray()  # Assuming X_train is in sparse format\n",
    "    model.fit(X_train_dense, y_train, epochs=800, batch_size=32, validation_split=0.2, verbose=0)\n",
    "\n",
    "    # Evaluate the model\n",
    "    X_test_dense = X_test.toarray()  # Assuming X_test is in sparse format\n",
    "    loss, accuracy = model.evaluate(X_test_dense, y_test, verbose=0)\n",
    "    return accuracy  # Return accuracy\n",
    "# Optuna study (maximize accuracy)\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=500)\n",
    "\n",
    "# Output best trial information\n",
    "print('Number of finished trials:', len(study.trials))\n",
    "print('Best trial:', study.best_trial.params)\n",
    "best_trial = study.best_trial\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train final model with best hyperparameters\n",
    "best_model = create_model(best_trial)\n",
    "X_train_dense = X_train.toarray()\n",
    "best_model_history = best_model.fit(X_train_dense, y_train, epochs=1000, batch_size=32, validation_split=0.2)\n",
    "loss, accuracy = best_model.evaluate(X_test_dense, y_test)\n",
    "print(f\"Test Accuracy: {accuracy*100:.2f}%\")\n",
    "\n",
    "# Save the final model\n",
    "best_model.save('best_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the untuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_model = load_model('ALE.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_allergens_with_user_input(model, vectorizer, mlb, threshold=0.5):\n",
    "    \"\"\"\n",
    "    Predicts allergens in a given food product based on user inputted ingredients\n",
    "    and provides the likelihood of each allergen.\n",
    "\n",
    "    Parameters:\n",
    "    - model: Trained machine learning model for prediction.\n",
    "    - vectorizer: CountVectorizer fitted on the training data.\n",
    "    - mlb: MultiLabelBinarizer fitted on the training data.\n",
    "    - threshold: Threshold for predicting the presence of an allergen (default is 0.5).\n",
    "\n",
    "    Returns:\n",
    "    - A dictionary with allergens and their likelihood.\n",
    "    \"\"\"\n",
    "\n",
    "    # User input\n",
    "    food_product = input(\"Enter Food Product Name: \")\n",
    "    main_ingredient = input(\"Enter Main Ingredient: \")\n",
    "    sweetener = input(\"Enter Sweetener (or None): \")\n",
    "    fat_oil = input(\"Enter Fat/Oil (or None): \")\n",
    "    seasoning = input(\"Enter Seasoning (or None): \")\n",
    "\n",
    "    # Combining the input data and transforming it using the vectorizer\n",
    "    combined_input = vectorizer.transform([f\"{food_product} {main_ingredient} {sweetener} {fat_oil} {seasoning}\"])\n",
    "\n",
    "    # Getting model predictions\n",
    "    pred_probabilities = model.predict(combined_input.toarray())[0]\n",
    "\n",
    "    # Creating a dictionary of allergen probabilities\n",
    "    allergen_probabilities = {allergen: prob for allergen, prob in zip(mlb.classes_, pred_probabilities)}\n",
    "    if '' in allergen_probabilities and allergen_probabilities[''] > threshold:\n",
    "        return f\"Does not contain allergens (Probability: {allergen_probabilities['']:.6f})\"\n",
    "    # Filtering to include only allergens with probability above the threshold\n",
    "    \n",
    "    likely_allergens = {allergen: prob for allergen, prob in allergen_probabilities.items() if prob > threshold}\n",
    "    if '' in likely_allergens:\n",
    "        return f\"Does not contain allergens (Probability: {allergen_probabilities['']:.6f})\"\n",
    "    else: \n",
    "        return likely_allergens\n",
    "  \n",
    "\n",
    "allergen_predictions = predict_allergens_with_user_input(trained_model, vectorizer, mlb)\n",
    "allergen_predictions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the tuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_trained_model = load_model('best_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_allergens_with_user_input(model, vectorizer, mlb, threshold=0.5):\n",
    "    \"\"\"\n",
    "    Predicts allergens in a given food product based on user inputted ingredients\n",
    "    and provides the likelihood of each allergen.\n",
    "\n",
    "    Parameters:\n",
    "    - model: Trained machine learning model for prediction.\n",
    "    - vectorizer: CountVectorizer fitted on the training data.\n",
    "    - mlb: MultiLabelBinarizer fitted on the training data.\n",
    "    - threshold: Threshold for predicting the presence of an allergen (default is 0.5).\n",
    "\n",
    "    Returns:\n",
    "    - A dictionary with allergens and their likelihood.\n",
    "    \"\"\"\n",
    "\n",
    "    # User input\n",
    "    food_product = input(\"Enter Food Product Name: \")\n",
    "    main_ingredient = input(\"Enter Main Ingredient: \")\n",
    "    sweetener = input(\"Enter Sweetener (or None): \")\n",
    "    fat_oil = input(\"Enter Fat/Oil (or None): \")\n",
    "    seasoning = input(\"Enter Seasoning (or None): \")\n",
    "\n",
    "    # Combining the input data and transforming it using the vectorizer\n",
    "    combined_input = vectorizer.transform([f\"{food_product} {main_ingredient} {sweetener} {fat_oil} {seasoning}\"])\n",
    "\n",
    "    # Getting model predictions\n",
    "    pred_probabilities = model.predict(combined_input.toarray())[0]\n",
    "\n",
    "    # Creating a dictionary of allergen probabilities\n",
    "    allergen_probabilities = {allergen: prob for allergen, prob in zip(mlb.classes_, pred_probabilities)}\n",
    "    if '' in allergen_probabilities and allergen_probabilities[''] > threshold:\n",
    "        return f\"Does not contain allergens (Probability: {allergen_probabilities['']:.6f})\"\n",
    "    # Filtering to include only allergens with probability above the threshold\n",
    "    \n",
    "    likely_allergens = {allergen: prob for allergen, prob in allergen_probabilities.items() if prob > threshold}\n",
    "    if '' in likely_allergens:\n",
    "        return f\"Does not contain allergens (Probability: {allergen_probabilities['']:.6f})\"\n",
    "    else: \n",
    "        return likely_allergens\n",
    "  \n",
    "\n",
    "allergen_predictions = predict_allergens_with_user_input(best_trained_model, vectorizer, mlb)\n",
    "allergen_predictions\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Seastell",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
